# -*- coding: utf-8 -*-
"""Submission_Template.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sac4qPbAxJGZpvIAbzKO9ZHfwchpOtnv

![dsc-logo](https://raw.githubusercontent.com/divyake/Cysec-Hacktoberfest/dcc84465cfcff73981f8fcb5c8fe3b1710c007e1/assets/logo.svg)

# Welcome to the AI Hacktoberfest for Developer Students Club IEM

```python
Hello World !

from AI import ForestFirePredictions
```

<img src='https://upload.wikimedia.org/wikipedia/commons/d/d8/Deerfire_high_res_edit.jpg' width='1200px' style="vertical-align:middle"/>

# Objective 

This Jupyter Notebook will help you get started with the Submissions and you can find details of this on our github repository [AI Hacktoberfest](https://github.com/dsc-iem/AI-Hacktoberfest). For details on submission procedure, view [this file](https://github.com/dsc-iem/AI-Hacktoberfest/blob/master/CONTRIBUTING.md). Also you can view a [brief description of the Dataset Features](https://github.com/dsc-iem/AI-Hacktoberfest/blob/master/README.md).

Forest Fires help in the natural cycle of woods' growth and replenishment clearing dead trees, leaves, and competing vegetation from the forest floor, so that new plants can grow, & remove weak or disease-ridden trees, leaving more space and nutrients for stronger trees.


But when fires burn too hot and uncontrollable or when they’re in the “wildland-urban interface” (the places where woodlands and homes or other developed areas meet), they can be damaging and life threatening.


In this project, our aim is to predict the burned area (`area`) of forest fires, in the northeast region of Portugal. Based on the the spatial, temporal, and weather variables where the fire is spotted. 

This prediction can be used for calculating the forces sent to the incident and deciding the urgency of the situation.

Further read:
1. [Mylandplan](https://mylandplan.org/content/good-and-bad-forest-fires)
2. [KNIME](https://www.knime.com/knime-applications/forest-fire-prediction)

# Fetching the Data
First of all we will be fetching the data from the repository by cloning it.
"""

!git clone https://github.com/dsc-iem/AI-Hacktoberfest

"""---"""

target = 'area'

"""---

# Define the metrics

**RMSE** 

RMSE is the most popular evaluation metric used in regression problems. It follows an assumption that error are unbiased and follow a normal distribution.

Further read: [Analyticsvidhya](https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/)

---

# Dependencies
"""

#libraries for linear algebra, data manipulations & data visualizations
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('dark_background')
#just a preference


#Feel free to import all your required libraries here.
#If needed include a requirements.txt file with all modules/dependencies with versions that you're using.
#Using old versions of Libraries is Not Recommended

import statsmodels.api as sm
from statsmodels.compat import lzip
import statsmodels.stats.api as sms
from statsmodels.formula.api import ols
from scipy.stats import zscore
from statsmodels.stats.stattools import durbin_watson
from sklearn.model_selection import train_test_split,KFold
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.metrics import mean_squared_error
from sklearn.feature_selection import RFECV
from mlxtend.feature_selection import SequentialFeatureSelector as sfs
from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs
from sklearn.linear_model import LinearRegression,RidgeCV,LassoCV,ElasticNetCV

"""---

# Load and describe data
"""

# path = 'forestfires.csv'
path = "/content/AI-Hacktoberfest/data/forestfires.csv"
df = pd.read_csv(path)

df.shape

df.dtypes

df.describe().T

"""---

# Missing value treatment
"""

df.isna().sum().sum()

"""---

# Exploratory Data Analysis
   We will try out the following analysis on our dataset
   - Univariate 
   - Bivariate 
   - Multivariate
"""

plt.rcParams["figure.figsize"] = 9,5

"""---

## Univariate analysis

### Let's begin with the target variable, `Area`
"""

plt.figure(figsize=(16,5))
print("Skew: {}".format(df[target].skew()))
print("Kurtosis: {}".format(df[target].kurtosis()))
ax = sns.kdeplot(df[target],shade=True,color='g')
plt.xticks([i for i in range(0,1200,50)])
plt.show()

ax = sns.boxplot(df[target])

"""**Few observations:**

- The data is highly skewed with a value of +12.84 and huge kurtosis value of 194.

- It even tells you that majority of the forest fires do not cover a large area, most of the damaged area is under 50 hectares of land.

- We can apply tranformation to fix the skewnesss and kurtosis, however we will have to inverse transform before submitting the output.

- Outlier Check: There are 4 outlier instances in our area columns but the questions is should we drop it or not? (Will get back to this in the outlier treatment step)
"""

# Outlier points
y_outliers = df[abs(zscore(df[target])) >= 3 ]
y_outliers

"""### Independent columns"""

dfa = df.drop(columns=target)
cat_columns = dfa.select_dtypes(include='object').columns.tolist()
num_columns = dfa.select_dtypes(exclude='object').columns.tolist()

cat_columns,num_columns

"""### Categorical columns"""

# analyzing categorical columns
plt.figure(figsize=(16,10))
for i,col in enumerate(cat_columns,1):
    plt.subplot(2,2,i)
    sns.countplot(data=dfa,y=col)
    plt.subplot(2,2,i+2)
    df[col].value_counts(normalize=True).plot.bar()
    plt.ylabel(col)
    plt.xlabel('% distribution per category')
plt.tight_layout()
plt.show()

"""1. It is interesting to see that abnormally high number of the forest fires occur in the month of `August`
and `September`.

2. In the case of day, the days `Friday` to `Monday` have higher proportion of cases. (However, no strong indicators)

### Numerical Columns
"""

plt.figure(figsize=(18,40))
for i,col in enumerate(num_columns,1):
    plt.subplot(8,4,i)
    sns.kdeplot(df[col],color='g',shade=True)
    plt.subplot(8,4,i+10)
    df[col].plot.box()
plt.tight_layout() 
plt.show()
num_data = df[num_columns]
pd.DataFrame(data=[num_data.skew(),num_data.kurtosis()],index=['skewness','kurtosis'])

"""Outliers, Skewness and kurtosis (high positive or negative) was observed in the following columns:
1. FFMC
2. ISI
3. rain

---

## Bivariate analysis with our target variable
"""

print(df['area'].describe(),'\n')
print(y_outliers)

# a categorical variable based on forest fire area damage
# No damage, low, moderate, high, very high
def area_cat(area):
    if area == 0.0:
        return "No damage"
    elif area <= 1:
        return "low"
    elif area <= 25:
        return "moderate"
    elif area <= 100:
        return "high"
    else:
        return "very high"

df['damage_category'] = df['area'].apply(area_cat)
df.head()

"""### Categorical columns"""

cat_columns

for col in cat_columns:
    cross = pd.crosstab(index=df['damage_category'],columns=df[col],normalize='index')
    cross.plot.barh(stacked=True,rot=40,cmap='hot')
    plt.xlabel('% distribution per category')
    plt.xticks(np.arange(0,1.1,0.1))
    plt.title("Forestfire damage each {}".format(col))
plt.show()

"""- Previously we had observed that `August` and `September` had the most number of forest fires. And from the above plot of `month`, we can understand few things
    - Most of the fires in August were low (< 1 hectare).
    - The very high damages(>100 hectares) happened in only 3 months - august,july and september.
 
- Regarding fire damage per day, nothing much can be observed. Except that, there were no ` very high` damaging fires on Friday and on Saturdays it has been reported most.

### Numerical columns
"""

plt.figure(figsize=(20,40))
for i,col in enumerate(num_columns,1):
    plt.subplot(10,1,i)
    if col in ['X','Y']:
        sns.swarmplot(data=df,x=col,y=target,hue='damage_category')
    else:
        sns.scatterplot(data=df,x=col,y=target,hue='damage_category')
plt.show()

"""---

## Multivariate analysis
"""

selected_features = df.drop(columns=['damage_category','day','month']).columns
selected_features

sns.pairplot(df,hue='damage_category',vars=selected_features)
plt.show()

"""---

# Outlier treatment

We had observed outliers in the following columns:
1. area 
2. FFMC
2. ISI
3. rain
"""

out_columns = ['area','FFMC','ISI','rain']

"""However, the above outliers are not error values so we cannot remove it. 

In order to minimize the effect of outliers in our model we will transform the above features. 

**Ref:** https://humansofdata.atlan.com/2018/03/when-delete-outliers-dataset/

---

# Preparing the data for modelling
Thing which we can cover here
- Encoding the categorical columns
"""

df = pd.get_dummies(df,columns=['day','month'],drop_first=True)

"""- Data transformations like `log,root,inverse,exponential`,etc"""

print(df[out_columns].describe())
np.log1p(df[out_columns]).skew(), np.log1p(df[out_columns]).kurtosis()

# FFMC and rain are still having high skew and kurtosis values, 
# since we will be using Linear regression model we cannot operate with such high values
# so for FFMC we can remove the outliers in them using z-score method
mask = df.loc[:,['FFMC']].apply(zscore).abs() < 3

# Since most of the values in rain are 0.0, we can convert it as a categorical column
df['rain'] = df['rain'].apply(lambda x: int(x > 0.0))

df = df[mask.values]
df.shape

out_columns.remove('rain')
df[out_columns] = np.log1p(df[out_columns])

df[out_columns].skew()

# we will use this final dataframe for building our ML model
df_ml = df.drop(columns=['damage_category']).copy()

df_ml.head()

df_x= df_ml.loc[:, df_ml.columns != target]
df_x.head()
#select all columns except the target and damage category for Xs

#convert all Xs to a numpy array for training
X=df_x.to_numpy()
X.shape

df_y=df_ml[target]
y=df_y.to_numpy()
y.shape

X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.3, random_state=42)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

X_train.head()

"""# Data Correlation"""

plt.figure(figsize =(16,10))

sns.heatmap(df_ml.corr(),annot=True,cmap='seismic',fmt=".2f",cbar=True) #'YlGnBu'
plt.show()

"""# Linear Regression
**In this section we will be working on Linear regression using Machine learning approach.**
"""

lr = LinearRegression()
l=lr.fit(X_train, y_train)

print(f'Intercept: {lr.intercept_}')
print(f'R^2 score: {lr.score(X_test, y_test)}')
pd.DataFrame({"Coefficients": lr.coef_}, index=X_train.columns)

"""# Improving ML model

You can always improve your Machine Learning Models by performing improvement techniques such as preprocessing, feature selection, feature engineering, dimensionality reduction etc. This step is customizable and can be improved substantially, or you can ignore this step.

## Feature Selection techniques

The following can be used for selecting relevant features for model building

1. **Using Pearson Correlation**
2. **Wrapper method** 
    1. Forward Selection: Forward selection is an iterative method in which we start with having no feature in the model. In each iteration, we keep adding the feature which best improves our model till an addition of a new variable does not improve the performance of the model.
"""

X_m, y_m = df_ml.drop(columns=[target]), df_ml[target]

"""### RFE"""

# RFECV is a variant with inbuilt Cross validation
model = LinearRegression()
selector = RFECV(model,cv=5)
selector = selector.fit(X_m, y_m)
print(f"Out of {len(X_m.columns)} features, best number of features {selector.n_features_}")
plt.figure()
plt.xlabel("Number of features selected")
plt.ylabel("Cross validation score")
plt.plot(range(1, len(X_m.columns) + 1), selector.grid_scores_)
plt.show()

# In our stats method we found that the intercept was not relevant 
# Let's try that feature out in our ML model
model = LinearRegression(fit_intercept=False)
selector = RFECV(model,cv=5)
selector = selector.fit(X_m, y_m)
print(f"Out of {len(X_m.columns)} features, best number of features {selector.n_features_}")

plt.figure()
plt.xlabel("Number of features selected")
plt.ylabel("Cross validation score")
plt.plot(range(1, len(X_m.columns) + 1), selector.grid_scores_)
print(X_m.columns[selector.support_].values)
plt.show()

"""**Building model with the best features and checking the R2 score for the same**"""

mask = selector.support_
print(f"Best features according to RFE {X_m.columns[mask].values}")

X_m1 = X_m.iloc[:,mask]
# We could have used train test split or cross validation strategies
# for scoring the model but in order to compare with the stats model 
# we will use the whole data
model1 = LinearRegression().fit(X_m1,y_m)
print(f"R2 Score: {model1.score(X_m1,y_m)}")

"""### Forward Selection"""

model = LinearRegression(fit_intercept=False)
sfs1 = sfs(model,k_features=20,forward=True,scoring='r2',cv=5)
sfs1.fit(X_m,y_m)
fig = plot_sfs(sfs1.get_metric_dict())
plt.title('Forward Selection')
plt.grid()
plt.show()

print(sfs1.k_features, sfs1.k_feature_names_,sep="\n")

index = list(sfs1.k_feature_idx_)
X_m1 = X_m.iloc[:,index]
model1 = LinearRegression().fit(X_m1,y_m)
print(f"R2 Score: {model1.score(X_m1,y_m)}")

"""## Regularization
1. Lasso
2. Ridge
3. ElasticNet

### Ridge
"""

# higher the alpha value, more restriction on the coefficients; 
# lower the alpha > more generalization, coefficients are barely
rr = RidgeCV(cv=5,fit_intercept=False) 
rr.fit(X_m, y_m)
rr.score(X_m,y_m)

rr.alpha_

plt.plot(rr.coef_,alpha=0.7,marker='*',markersize=10,color='red',label=r'Ridge; $\alpha =10$') 
plt.grid(True)
plt.xticks(range(0,28,1))
plt.legend()
plt.show()

"""# Model Accuracy Metrics

You must use the Mean Squared Error & Mean Absolute Error for your model evaluations. You may also include extra metrics for calculating the scores.
"""

def MSE(model_preds, ground_truths):
  return "Your code here"

def MAE(model_preds, ground_truths):
  return "Your code here"

def Other_Err(model_preds, ground_truths):
  return "Your code here"

"""# Metric Reports
Report your metrics in the following manner : 

| Metrics 	| Values 	| Comments 	|
|-	|-	|-	|
| MSE 	| 3.80 	| A 	|
| MAE 	| 1.00 	| B 	|
| Others 	| 1.35 	| C 	|

# Final Note

You can also provide drive links to saved model files along with their working notebook demos like this :

View the drive source for this file here : [Submission_Template.ipynb](https://drive.google.com/drive/folders/1nkpvgPF3SrDe-a0NAXkTTaxBtaewCuus?usp=sharing)
"""